---
title: "COVID-19 EDA"
author: 
        - Byron Smith (300504707)
        - Iona Sammons (300281718)
        - Lauren Halka (300346046)
date: "05/08/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background and Data

### Dataset and Source
The dataset we are using is the `Covid 19 data portal` dataset developed and maintained by Stats NZ. The source of the data is from numerous sources including New Zealand government agencies such as the Reserve Bank of New Zealand, The Treasury and the Ministry of Social Development, banks and other international sources.

### Why is the dataset of interest?
The data set includes data on three main categories; Economic, Health and Social. Each of these categories has a number of sub categories which have different indicators such as, Boradband Usage and Border Crossings. The majority of the indicators are New Zealand based but there are also a few indicators to do with other countries eg. US Economic Index.  

  As most of the data is New Zealand based, it will be useful for answering a number of questions about the impact of COVID-19 and the Alert Level restrictions. An example of a question we may want to answer is: What is the effect of an Alert Level increase/ decrease on the NZD foreign exchange rate with USD? To answer this we would look at the timeseries data on NZD/USD exchange and find the Alert Level announcement and commencement dates.
  
  Another question we could look at is: How many people have not left New Zealand due to COVID-19? This would be answered by looking at daily border crossings (departures), where we would model a prediction, had COVID-19 not had any effect, versus what we actually saw.

### Data types and structure

##### Structure 
The dataset is structured in a tree like pattern, where there are four main classes, which each have a number of categories with a number of indicators. Some indicators also contain sub-categories which splits the data into categories such as City or Type of Passport. This is represented in the dataset with columns called `class`, `category`, `indicator_name` and `sub_series`. 

  Some indicators also have multiple series which cover the same time period. For example the indicator `Card transaction total spend` has the actual amount spent, the seasonally adjusted amount spent and the number of transactions.

  There are three columns which contain the actual time series information. These columns have the date, value and unit of measure. The values of different indicators have a number of units of measure including dollars, tonnes, percentage, percentage per annum, index and number.  
  
  The last column is the date that the data for the indicator was last updated. This appears to apply to all the indicator values for all dates and not just the most recent value added to the indicator.
  
##### Types
All the columns in the dataset are character types. The columns `parameter` and `value` will need to be changed to other types before these columns can be used. However, as some values are integers while others are floats it would be wise to only change the type once we have extracted the subset we are going to work on. Similarly with the dates, the formats are generally the same but differ for certain indicators.

### Completeness and Correctness
The dataset has 76 rows that have missing values in the `value` column. These missing values are mostly limited to three indicators and cover a certain time period for each indicator: Electricity Grid Demand (Oct 2003 - Mar 2005), New Jobs Posted Online (Oct 2003 - Dec 2004), Christchurch Heavy Vehicles (03 Dec 2018 - 05 Mar 2019). There is also one row with a missing value for the indicator, Fuel Supply.   

  As the dataset is so large it is hard to determine if there are obvious errors in the data. We will need to wait until we are looking at subsets of the data to pick up on any errors. However, we have visualized different subsets of the data using the Stats NZ COVID-19 data portal tool and have not seen any obvious errors so we can be relatively confident the majority of the data is error free.


### Integration steps

---

## Ethics, Privacy and Security

### Ethical Considerations

Ethics in the data science process, at its core, revolves around the idea of ensuring that any data associated with a given project is ethically sourced.  In the context of the COVID-19 Data Portal, this in turn, firstly, involves considering whether informed consent was collected prior to the gathering/integrating of new and existing data, to ensure that all of those individuals represented in the figures and statistics of the portal, are aware that data linking back to them is being used and for what reason.

As the portal brings together data from multiple external sources (as well as utilising its own), ensuring informed consent was received in this particular setting is clearly questionable.  The process of tracking down and informing each individual (who contributed their data to the portal) of the prospective use and distribution of their data would be an extremely complex and timely exercise.  Because the data in the portal itself takes an aggregate format, and thus does not present data of individuals, it could also be questioned whether the above detail in terms of informed consent is required.  As the portal utilises data from other government organisations, it could be assumed that appropriate agreements have been made between each source and those individuals whose data were collected, to distribute it for research purposes.

Another angle from which ethics should be considered in this case, relates to the application of Māori Data Sovereignty principles (https://cdn.auckland.ac.nz/assets/psych/about/our-research/documents/TMR%2BM%C4%81ori%2BData%2BSovereignty%2BPrinciples%2BOct%2B2018.pdf).  The COVID-19 Portal mainly concerns data relating to the state of economic, health and social factors in New Zealand (with the addition of some international data for the sake of comparison only), for which reason this consideration is so crucial.  Although the portal aggregates data, it fails to create additional attributes that showcase data relating to and representing Māori.  Because of this, Māori are unable to identify with the portal, and have clear control over their data through subjecting it to  Māori governance.

### Privacy Concerns

Stats NZ ensures that data published does not identify individuals, households or businesses as stated on their Privacy, Security and Confidentiality page. (http://archive.stats.govt.nz/about_us/legisln-policies-protocols/confidentiality-of-info-supplied-to-snz.aspx#gsc.tab=0).

However we must ensure that when using the data we do not make any effort to identify any individual party that contributed information to Stats NZ to create the data set. We may in the future obtain data which when paired with the COVID-19 Data Portal dataset may allow us to identify individual parties. We should again ensure we make no effort to identify these parties and when publishing our results, ensure that the parties are anonymized and the results cannot be used to identify individual parties. 

### Security of data

To address the issue of security and potential problem areas with the data required for this project, we will assess it according to the principles contained within the CIA Triad - Confidentiality, Integrity and Availability. 

#### Confidentiality

As we are using publicly available data, we are trusting that Stats NZ will ensure the security of the data up to the point that we download it.  For them to do this successfully, they will securely work with data they are aggregating, so that no individual can gain unauthorised access to it, thus protecting the data from being tampered with or unlawfully distributed.  Furthermore, to protect the privacy of the individuals behind the data, Stats NZ will need to ensure that no data is personally identifiable, which when taking into consideration this data works with totals and aggregates, this should not be an issue, however, it does pay to mention it.

#### Integrity

When considering the process in which Stats NZ undertakes to collate the COVID-19 Data Portal, the fact that it is updated daily to provide new data demonstrates commitment to ensuring the data is as relevant as it can possibly be.  However, because they are collating data from other Government organisations, although they can ensure the quality and integrity of the data in which they collect themselves, they cannot promise the same of those collected externally.  With this in mind, Stats NZ has, however, made a disclaimer surrounding this issue.

Once downloaded, the main risk to the data will be integrity, where it is modified without our knowledge. One way that we can ensure that the integrity of the data is by using version tracking through git which will show any modifications made to the data after download. This will ensure, if we see no changes, that the data downloaded is the same as that on Stats NZ website, which we can assume to be correct. 

#### Availability

Assessing availability involves looking at the ability of mechanisms to perform appropriately and grant access to the data when required.  As a publicly available dataset that is updated daily and can be downloaded from the COVID-19 Data Portal with the simple click of a button, there are no apparent issues here.

#### How will we keep project data and results secure?

Keeping the above in mind when answering this part of the question, keeping project data and results secure in this context is more about carrying out measures to prevent work from being lost, as opposed to doing so alongside protecting sensitive data from being leaked - because we are utilising a public data source.  Consequently, to do this, we will ensure we back up all progress when working with R code through committing it to our Github repository.  However, if we were working with sensitive data, to keep these results secure, we would take a further step and set our repository to private, ensuring that it can only be accessed by members of our team.  


---

## Exploratory Data Analysis

### Overall EDA
```{r message = FALSE}
# import packages
library(dplyr)
```
```{r}
# import the data set
covid <- read.csv("covid_19_data_portal.csv", header = TRUE, stringsAsFactors = FALSE)
```
```{r}
# check how many rows have missing values
nrow(covid[rowSums(is.na(covid)) > 0,])
```
```{r}
# remove rows with NA
covid <- na.omit(covid)
```

```{r}
head(covid)
```

### EDA 1



```{r}
length(unique(covid$indicator_name))
```


The function `get.frequency` finds the frequency of instances of a given dataset (subset of covid with a single indicator)
```{r message = F}
library(xts)
# get the time frequency 
# df : subset of covid with one indicator_name value
get.frequency <- function(df) {
  # check if indicator has multiple series
  ind.sub <- df
  if(length(unique(ind.sub$series_name)) > 1 || length(unique(ind.sub$sub_series_name)) > 1){
    ind.sub <- get.single.series(ind.sub)
  }
  # get time frequency of instances with periodicity function
  avg.dif <- periodicity(ind.sub$parameter)
  return(avg.dif$scale)
}
```

The function `get.single.series` removes all but one series / sub series so that only one time period is left.
```{r}
# get the single series for indicator
get.single.series <- function(df) {
  ans <- df %>% filter(series_name == unique(df$series_name)[1])
  # check for multiple sub series
  if(length(unique(ans$sub_series_name)) > 1)
    ans <- ans %>% filter(sub_series_name == unique(df$sub_series_name)[1])
  return(ans)
}
```

Here we create a new data frame of all the indicators and their frequencies. We get a table with frequency counts and `ind.freqs.df`, which can be used to filter the large data set by frequency or lookup the frequency for an indicator.
```{r message = F}
# get instance frequency for all indicators
# convert parameter to date
covid.1 <- covid
covid.1$parameter <- as.Date(covid.1$parameter)
# remove NA dates
covid.1 <- na.omit(covid.1)

indicators <- unique(covid.1$indicator_name)
frequency <- c()
for(i in 1:length(indicators)) {
  ind.sub <- covid.1 %>% filter(indicator_name == indicators[i])
  frequency <- append(frequency, get.frequency(ind.sub))
}
ind.freqs <- cbind(indicators, frequency)
ind.freqs.df <- as.data.frame(ind.freqs)

freq.totals <- ind.freqs.df %>% group_by(frequency) %>% summarise(total = n()) %>% arrange(total)
```
```{r}
library(ggplot2)
ggplot(freq.totals, aes(x=reorder(frequency, total), y=total)) +
  geom_bar(stat="identity", fill = "steelblue") + 
  geom_text(aes(label=total), vjust=1.6, color="white", size=3.5) +
  labs(x = "Frequency", y = "Number of indicators", title = "Instance frequencies of indicators in COVID-19 dataset") +
  theme(panel.background = element_rect(fill = "white", colour = "gray90", size = 1),
          panel.grid.major = element_line(size = 0.7, linetype = 'solid', colour = "gray97"))
```
  
The COVID-19 dataset contains daily, weekly and monthly timeseries data. The majority of the indicators have monthly instances. 


##### Time period covered
When looking at what questions we may be able to answer with this data we also need to know how much information we have for each indicator in terms of time period covered. We will add this information to the dataframe holding the indicator frequencies to gain more insight about the indicators overall.

```{r}
# get start and end dates for each predictor
start.date = c()
end.date = c()
for(i in 1:nrow(ind.freqs.df)){
  tmp <- covid.1 %>% filter(indicator_name == ind.freqs.df$indicators[i])
  start.date <- append(start.date, tmp$parameter[1])
  end.date <- append(end.date, tmp$parameter[nrow(tmp)])
}

# create a data frame with indicator info (add to frequency data)
indicator.info <- ind.freqs.df
indicator.info$start.date <- start.date
indicator.info$end.date <- end.date
# make new column with approximate length (days and months and years)
indicator.info <- indicator.info %>% 
  mutate(time.range.day = end.date - start.date, 
         time.range.month = round((end.date - start.date) / 30),
         time.range.year = round((end.date - start.date) / 365))
indicator.info$time.range.day <- as.numeric(indicator.info$time.range.day, units="days")
indicator.info$time.range.month <- as.numeric(indicator.info$time.range.month, units="days")
indicator.info$time.range.year <- as.numeric(indicator.info$time.range.year, units="days")
```
```{r}
ggplot(indicator.info, aes(x = time.range.year)) + 
  geom_histogram(binwidth = 1, alpha = 0.8, fill = "steelblue") +
  labs(x = "Years of data", y = "Number of indicators", title = "Indicator time range") +
  theme(panel.background = element_rect(fill = "white", colour = "gray90", size = 1),
          panel.grid.major = element_line(size = 0.7, linetype = 'solid', colour = "gray97"))
```

```{r}
ggplot(indicator.info, aes(x = time.range.year, fill = frequency)) + 
  geom_histogram(binwidth = 1, alpha = 0.8) +
  scale_fill_ordinal() +
  labs(x = "Years of data", y = "Number of indicators", title = "Indicator time range") +
  theme(panel.background = element_rect(fill = "white", colour = "gray90", size = 1),
          panel.grid.major = element_line(size = 0.7, linetype = 'solid', colour = "gray97"))
```

We can see that most indicators have a relatively short time frame with the majority only going back 1 year. We can also see that the indicators which have less than a years worth of data have short frequencies, daily and weekly. 

From this plot we can see that there are a few indicators which have a daily frequency and go back about 5 years.
```{r}
filter(indicator.info, time.range.year == 5 & frequency == "daily")$indicators
head(indicator.info)
```




### EDA 2
```{r}
# Select data that relates to departures
allDepartures <- filter(covid, indicator_name == "Daily border crossings - departures")

# Convert values from char to correct format
allDepartures$parameter <- as.Date(allDepartures$parameter, format="%Y-%m-%d")
allDepartures$value <- as.numeric(allDepartures$value)

# Select NZ passport departures
nzDepartures <- filter(allDepartures, series_name == "New Zealand passport")

# See what we gots...
plot(allDepartures$parameter, allDepartures$value)
plot(nzDepartures$parameter, nzDepartures$value)

# Narrow it down
firstReportedCase <- as.Date("2020-02-28")
bordersClosed <- as.Date("2020-03-19")
levelFour <- as.Date("2020-03-25")
MIQStarted <- as.Date("2020-04-10")
levelThree <- as.Date("2020-04-27")
levelTwo <- as.Date("2020-05-13")
levelOne <- as.Date("2020-06-08")
MIQFeeCameIntoEffect <- as.Date("2020-08-11")

recentNzDepartures <- filter(nzDepartures, parameter > firstReportedCase)
ggplot(recentNzDepartures, aes(x=parameter, y=value)) + 
  geom_line() +
  geom_vline(xintercept = bordersClosed, color = "blue") +
  geom_vline(xintercept = levelFour, color = "red") +
  geom_vline(xintercept = levelThree, color = "orange") +
  geom_vline(xintercept = levelTwo, color = "yellow") +
  geom_vline(xintercept = levelOne, color = "green") +
  geom_vline(xintercept = MIQFeeCameIntoEffect, color = "blue")
```

### EDA 3

Exploratory Data Analysis is all about the process of better understanding the data one is working with.  As mentioned at the beginning of this analysis, this COVID-19 portal has its data structured like a decision tree, containing categorical variables to help group the key attribute, ‘parameter’.  The first defining attribute is that of 'class', determining whether data relates to Economic, Health, Social or Wellbeing factors.  Of the 112,382 observations in the cleaned version of the COVID-19 Data Portal (whereby rows containing NA values were omitted), the following visualisation shows how the classifications are distributed amongst all current observations.

```{r}

covid_class_summary <- covid %>% group_by(class) %>% summarize(count=n())
covid_class_summary <- as.data.frame(covid_class_summary)

ggplot(covid_class_summary, aes(x=class, y=count, fill=class)) + 
  geom_bar(stat = "identity") +
  xlab("Class") + ylab("No. of Observations") 
  
```

The above goes to show that the clear majority of observations kept within this portal are associated with ‘Economic’ factors.  ‘Health’ too contains a significant number of observations, which would be assumed as being associated with COVID-19 related statistics as that is what the portal was created for.  Something interesting to note is the 24 ‘Wellbeing’ related observations, which are so insignificant and hence do not appear on the graph.  In Stats NZ’s description, this classification is not one of the three mentioned, for which reason it should be further investigated, and potentially moved under the ‘Health’ category, if appropriate, to ensure it is accounted for in analysis.

```{r}
  
# creating a subset of the covid data that contains only those classified as 'Wellbeing'
investigation <- filter(covid, class=="Wellbeing")

# only including the first three columns as they best summarise the categories of each observation
investigation <- investigation[,1:3]

# defining the unique observation types that come under the wellbeing category
distinct(investigation)
  
```
Upon further investigation - results as shown in the above table - the 24 observations that were classified as ‘Wellbeing’, came under 3 distinct combinations of the attributes ‘class’, ‘category’, and ‘indicator_name’.  When considering they fall under categories associated with crime and social connection, it would make sense to instead move all of these observations under the ‘Social’ class.


---


## Individual Contributions









